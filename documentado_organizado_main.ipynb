{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPOORC89RJ56vuG+RY82Y/5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuanAcevedo08/JuanAcevedo08/blob/main/documentado_organizado_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 Importacion de datos"
      ],
      "metadata": {
        "id": "Np0haV66gzT2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2Igo7KwfhgX"
      },
      "outputs": [],
      "source": [
        "#De GCP vamos a acceder donde se encuentran los datos desde la nube para poder cargalos\n",
        "!wget --no-check-certificate https://storage.googleapis.com/platzi-tf2/sign-language-img.zip \\-O /tmp/sign-language-img.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile #Librería para manejar archivos zip\n",
        "import os  #Poder acceder al sistema operativo para manejar rutas"
      ],
      "metadata": {
        "id": "NSemwt6Pf0Mi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_ = \"/tmp/sign-language-img.zip\" #Accedemos a la ruta donde se encuentra el archvio zip\n",
        "zip_file = zipfile.ZipFile(file_) #Convertimos en un archivo zip lo que estaba en esa ruta\n",
        "zip_file.extractall(\"/tmp/sign-language-img\") #Extraemos todos los valores del archivo zip que acababamos de crear\n",
        "zip_file.close() #Cerramos el archivo para no consumir mas espacio"
      ],
      "metadata": {
        "id": "BKxEun7gg7p1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 Importacion de librerías y creacion de generadores\n",
        "\n"
      ],
      "metadata": {
        "id": "bjiJAGFPhoWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np #Uso de algebra lineal\n",
        "import string #Manejo de strings\n",
        "# Aprovechar mejor graficas\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt #Graficar\n",
        "import tensorflow as tf #Librería para uso de redes neuronales\n",
        "image_generators = tf.keras.preprocessing.image.ImageDataGenerator #Generador de imagenes: Este se encarga de recorrer nuestras imagenes y pasarlas como entranamiento"
      ],
      "metadata": {
        "id": "QZUSpX6PhvHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Estructura del generador de entrenamiento\n",
        "train_gen_est = image_generators(rescale=1/255) #Normalizo las imagenes , para que sea mucho mejor los resultados\n",
        "test_gen_est = image_generators(rescale=1/255, validation_split=0.2) #Normalizo acá también y separo para el de validación"
      ],
      "metadata": {
        "id": "U0LqzH8ziQOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Rutas de donde saldrán las imágenes\n",
        "train_path = '/tmp/sign-language-img/Train' #Donde saldrá para entrenar el modelo\n",
        "test_path = '/tmp/sign-language-img/Test' #Acá saldrá para validar el modelo durante y después de acabar de entrenar"
      ],
      "metadata": {
        "id": "GJhDo_zgjw_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "                                        #Ajustar los generadores\n",
        "#---- Generador de entrenamiento ----\n",
        "train_gen = train_gen_est.flow_from_directory(\n",
        "    train_path, #De dondé saldrán las imágenes\n",
        "    target_size=(28, 28), #El tamaño de las imágenes (Importante que todas sean del mismo tamaño)\n",
        "    color_mode='grayscale', #La escala de las imágenes\n",
        "    class_mode='categorical', #Tipo de clase que hay\n",
        "    batch_size=(128), #Tamaño del lote en como va enviar las imágenes\n",
        "    subset='training' #Que tipo de set de datos será este\n",
        ")\n",
        "\n",
        "#---- Generador de validación  ----\n",
        "validation_gen = test_gen_est.flow_from_directory(\n",
        "    test_path, #De dondé saldrán las imágenes\n",
        "    target_size=(28, 28), #El tamaño de las imágenes (Importante que todas sean del mismo tamaño)\n",
        "    color_mode='grayscale', #La escala de las imágenes\n",
        "    class_mode='categorical', #Tipo de clase que hay\n",
        "    batch_size=(128), #Tamaño del lote en como va enviar las imágenes\n",
        "    subset='validation' #Que tipo de set de datos será este\n",
        ")\n",
        "\n",
        "#---- Generador de test ----\n",
        "test_gen = test_gen_est.flow_from_directory(\n",
        "    test_path, #De dondé saldrán las imágenes\n",
        "    target_size=(28, 28), #El tamaño de las imágenes (Importante que todas sean del mismo tamaño)\n",
        "    color_mode='grayscale', #La escala de las imágenes\n",
        "    class_mode='categorical', #Tipo de clase que hay\n",
        "    batch_size=(128), #Tamaño del lote en como va enviar las imágenes\n",
        "    #Al definir train y validation sets el set de test ya se reconoce automaticamente\n",
        ")"
      ],
      "metadata": {
        "id": "CWcFKxn2jQN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Funcion de graficacion de imagenes y mostrar primeras imagenes"
      ],
      "metadata": {
        "id": "354axpTumM7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plto_image(image):\n",
        "  \"\"\"\n",
        "  Creo 5 columnas en 1 fila donde irán las imagenes , fijo también el tamaño que va a tener por imagen\n",
        "  realizo un flaten en los axes para que sea mas facíl de graficar\n",
        "  itero por cada imagen que se ponga y por cada ax para poder mostrar la iamgen con toda la fila y columna de la matriz diciendo que solo queremos el color en bloque 1\n",
        "  retiro el axis para que sea mejor visiblemente\n",
        "  realizo un tigh_layout para que no se sobrepongan algunas imagenes entre si\n",
        "  finalmente muestro las imagenes creadas\n",
        "  \"\"\"\n",
        "  fig, axes = plt.subplots(1, 5, figsize=(12, 10))\n",
        "  axes = axes.flatten()\n",
        "  for img, ax in zip(image, axes):\n",
        "    ax.imshow(img[:, :, 0])\n",
        "    ax.axis('off')\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "-2MgyK26mTz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Recorrer todas las imagenes del set de entrenamiento\n",
        "image, _ = next(train_gen)\n",
        "#Graficar las primeras 5 imagenes\n",
        "plto_image(image[:5])"
      ],
      "metadata": {
        "id": "glKidpG7m5-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 Clases\n",
        "\n",
        "Esta parte es importante ya que serán la cantidad de neuronas que va a llevar nuestra red neuronal al momento de la capa final , como est capa final nos tiene que dar el valor de cada una de las clases para poder determinar cual de las es la elegida de esa manera para cualquier nn hay que poner las clases que tenemos y la longitud de la clase\n",
        "\n",
        "ejemplo: tengo un trabajo de clasificar tipos de celular , tengo 8 clases pues las neuronas finales serían 8"
      ],
      "metadata": {
        "id": "-qjWOCoHFRny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clases =  [char for char in string.ascii_uppercase if char != 'J' if char !='Z']\n",
        "len(clases)"
      ],
      "metadata": {
        "id": "WiCz6n_MFV0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 Graficador de resultados\n"
      ],
      "metadata": {
        "id": "s7vUSF-wGZMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history):\n",
        "\n",
        "  epochs = [v for v in range(20)]\n",
        "\n",
        "  fig, ax = plt.subplots(1, 2)\n",
        "\n",
        "  fig.set_size_inches(16, 10)\n",
        "\n",
        "  train_acc = history.history['accuracy']\n",
        "  val_acc = history.history['val_accuracy']\n",
        "\n",
        "  train_loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  ax[0].plot(epochs, train_acc, 'g-o', label='Accuracy train')\n",
        "  ax[0].plot(epochs, val_acc, 'r-o', label='Accuracy validation')\n",
        "  ax[0].set_title('Accuracy Plots')\n",
        "  ax[0].legend()\n",
        "  ax[0].set_xlabel('Epochs')\n",
        "  ax[0].set_ylabel('Accuracy')\n",
        "\n",
        "  ax[1].plot(epochs, train_loss, 'g-o', label='Loss train')\n",
        "  ax[1].plot(epochs, val_acc, 'r-o', label='Loss validation')\n",
        "  ax[1].set_title('Loss Plots')\n",
        "  ax[1].legend()\n",
        "  ax[1].set_xlabel('Epochs')\n",
        "  ax[1].set_ylabel('Loss')\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "RMlhPdqIGaEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6 **REDES NEURONALES**"
      ],
      "metadata": {
        "id": "Yu1v0jaUceBd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.1 NN normal base\n"
      ],
      "metadata": {
        "id": "-jjSqA0En3Jy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nn_basic():\n",
        "  model_base = tf.keras.Sequential([\n",
        "  #1. Capa inicial flatten con el indicador de tamaño\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
        "  #2. Segunda capa con 256 neuronas y relu\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\n",
        "  #3. Tercera capa con 128 neuronas y relu\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  #4. Capa final con el valor de las clases para clasificar\n",
        "  tf.keras.layers.Dense(len(clases), activation='softmax')\n",
        "  ])\n",
        "  return model_base\n",
        "\n",
        "#Creacion del modelo base\n",
        "model_base = nn_basic()\n",
        "#Compilar el modelo para utilizar luego\n",
        "model_base.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "#Mostrar estructura\n",
        "model_base.summary()"
      ],
      "metadata": {
        "id": "bg0NpVtIoBVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.2 NN con regularizadores y dropout\n",
        "\n"
      ],
      "metadata": {
        "id": "fFYUCYfnKUt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regularizer = tf.keras.regularizers"
      ],
      "metadata": {
        "id": "S48D5nRKKab5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nn_regularizer():\n",
        "  model_regularizer = tf.keras.Sequential([\n",
        "  #1. Iniciar con flatten para mejorar el proceso de la nn\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
        "  #2. Capa incial que recibe entradas\n",
        "  tf.keras.layers.Dense(256, kernel_regularizer=regularizer.l2(1e-5), activation='relu'),\n",
        "  #3. Aplica dropout a la capa 2\n",
        "  tf.keras.layers.Dropout(rate=0.2),\n",
        "  #4. Capa que recibe la segunda capa como entrada\n",
        "  tf.keras.layers.Dense(128, kernel_regularizer=regularizer.l2(1e-5), activation='relu'),\n",
        "  #5. Aplica un dropout a la capa numero 4\n",
        "  tf.keras.layers.Dropout(rate=0.2),\n",
        "  #6. Finalmente recibe la informacion de las capas anteriores y devuelve las probabilidades de las clases para clasificar\n",
        "  tf.keras.layers.Dense(len(clases), activation='softmax')\n",
        "  ])\n",
        "\n",
        "  return model_regularizer\n",
        "\n",
        "#Crear el modelo\n",
        "model_regularizer = nn_regularizer()\n",
        "#Mostrar estructura\n",
        "model_regularizer.summary()"
      ],
      "metadata": {
        "id": "cEr5cYLvKYgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.3 CNN con regularizadores"
      ],
      "metadata": {
        "id": "ROwgRulaSeCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cnn_model():\n",
        "  model_cnn = tf.keras.Sequential([\n",
        "  #1. Capa convolucional para extraer las caracteristicas principales\n",
        "  tf.keras.layers.Conv2D(75, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  #2. Capa que se encarga de eliminar aquello que no está en las caracteristicas principales\n",
        "  tf.keras.layers.MaxPool2D((2, 2)),\n",
        "  #3. Capa para convertir los datos en vector para empezar a procesarlos en la red\n",
        "  tf.keras.layers.Flatten(),\n",
        "  #4. Primera capa de operaciones 256 neuronas\n",
        "  tf.keras.layers.Dense(256, kernel_regularizer=regularizer.l2(1e-5), activation='relu'),\n",
        "  #5. Capa de dropout para capa 4\n",
        "  tf.keras.layers.Dropout(rate=0.2),\n",
        "  #6. Capa de 128  neuronas\n",
        "  tf.keras.layers.Dense(128, kernel_regularizer=regularizer.l2(1e-5), activation='relu'),\n",
        "  #7. Capa de dropout para capa 6\n",
        "  tf.keras.layers.Dropout(rate=0.2),\n",
        "  #8. Capa final con los valores de 1las clases para clasificar\n",
        "  tf.keras.layers.Dense(len(clases), activation='softmax')\n",
        "  ])\n",
        "\n",
        "  return model_cnn\n",
        "#Crear el modelo\n",
        "model_cnn = cnn_model()\n",
        "#Compilar modelo para usarlo luego\n",
        "model_cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "#Mostrar estructura del modelo\n",
        "model_cnn.summary()"
      ],
      "metadata": {
        "id": "P1d40dJTSitC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7 **CALLBACKS**"
      ],
      "metadata": {
        "id": "QHcuAaGYczNS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.0 Importacion de los callbacks necesarios"
      ],
      "metadata": {
        "id": "o1geAvLVf5Dr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, EarlyStopping, TensorBoard"
      ],
      "metadata": {
        "id": "AaMdUmxade_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.1 Callbacks manuales"
      ],
      "metadata": {
        "id": "5Pq42zMDgAoy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Callback para train\n",
        "Para estos call back es importante conocer los metodos que tiene la clase padre para que esto pueda funcionar\n",
        "Metodos[on_set_begin, on_epoch_begin, on_set_batch_begin, on_set_batch_end, on_epoch_end, on_set_end]\n",
        "Donde set = (train, test, prediction)\n",
        "### -on_set_begin = Momento donde empieza el set\n",
        "### -on_epoch_begin = Momento donde empieza el primer epoch es decir la primera iteracion\n",
        "### -on_set_batch_begin = Momento donde el lote del set empieza\n",
        "### -on_set_batch_end = Momento donde el lote del set finaliza\n",
        "### -on_epoch_end = Momento donde acaba la iteracion\n",
        "### -on_set_end = Momento donde acaba de iterar el set\n",
        "\n",
        "Así mismo para test y predicción\n",
        "\n",
        "### -epoch = cantidad de iteraciones\n",
        "### -logs = contiene los registros de cada iteracion para poder consultar\n",
        "### -batch = lote a utilizar"
      ],
      "metadata": {
        "id": "qEUeTixUh-d_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train callback\n",
        "class TrainingCallback(Callback):\n",
        "  def on_train_begin(self, logs=None):\n",
        "    print('Starting training....')\n",
        "\n",
        "  def on_epoch_begin(self, epoch, logs=None):\n",
        "    print(f'Starting epoch {epoch}')\n",
        "\n",
        "  def on_train_batch_begin(self, batch, logs=None):\n",
        "    print(f'Training: Starting batch {batch}')\n",
        "  def on_train_batch_end(self, batch, logs=None):\n",
        "    print(f'Training: Finished batch {batch}')\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    print(f'Finished epoch {epoch}')\n",
        "\n",
        "  def on_train_end(self, logs={}):\n",
        "     print('Finished training!')\n",
        "     if logs.get('accuracy') >0.95:\n",
        "      print(\"Lo logramos, nuestro modelo llego a 95%, detenemos el entrenamiento\")\n",
        "      self.model.stop_training = True\n",
        "#Test Callback\n",
        "\n",
        "class TestingCallback(Callback):\n",
        "  def on_test_begin(self, logs=None):\n",
        "    print('Starting testing....')\n",
        "\n",
        "  def on_test_batch_begin(self, batch, logs=None):\n",
        "    print(f'Testing: Starting batch {batch}')\n",
        "\n",
        "  def on_test_batch_end(self, batch, logs=None):\n",
        "    print(f'Testing: Finished batch {batch}')\n",
        "\n",
        "  def on_test_end(self, logs=None):\n",
        "     print(f'Finished testing!')\n",
        "\n",
        "#Prediction - Validate Callback\n",
        "class PredictionCallback(Callback):\n",
        "  def on_predict_begin(self, logs=None):\n",
        "    print('Prediction testing....')\n",
        "\n",
        "  def on_predict_batch_begin(self, batch, logs=None):\n",
        "    print(f'Prediction: Starting batch {batch}')\n",
        "\n",
        "  def on_predict_batch_end(self, batch, logs=None):\n",
        "    print(f'Prediction: Finished batch {batch}')\n",
        "\n",
        "  def on_predict_end(self, logs=None):\n",
        "     print('Finished prediction!')"
      ],
      "metadata": {
        "id": "LpO2g0rQgPI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.2 Early Stopping"
      ],
      "metadata": {
        "id": "PGHqaFwKiSkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_callback = EarlyStopping(monitor='loss', patience=3, mode='auto')\n",
        "#Monitor: Se refiere a la funcion a evaluar para no sobreajustar , ya sea perdida, accuracy etc\n",
        "#Patience: La cantidad de iteraciones adicionales que va esperar para detenerse\n",
        "#Mode: Depende de la funcion a monitorear lo que buscamos es minimizar o maximizar\n",
        "#Ejemplo: Este empeiza las iteraciones , eleccionamos monitor: Accuracy y mode='auto' ,\n",
        "#este va a iterar para alcanzar el accuracy mas alto cuando este ya no cambie va esperar 3 iteraciones mas, si este no cambia en esas 3 iteraciones , para el entrenamiento"
      ],
      "metadata": {
        "id": "YMtoa2KxkWKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.3 ModelCheckPoint"
      ],
      "metadata": {
        "id": "B5NUniEtlag9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Este se encarga de almacenar estructura y pesos de la red nueronl para poder volver a utilizarse , mostraré dos ejemplos de solo guardar pesos y otro de guardar todo el modelo\n",
        "#1. Solo guardar los pesos\n",
        "#Ruta donde se almacenan los pesos\n",
        "weights_path = \"model_weights/checkpoints.weights.h5\"\n",
        "checkpoint_weights = ModelCheckpoint(filepath=weights_path, save_weights_only=True, save_freq='epoch', verbose=1)\n",
        "#filpath: La ruta donde va guardar los pesos\n",
        "#save_weights_only: Solamente va guardar los pesos nada mas,\n",
        "#save_freq: Cada cuanto va guardar los pesos en este caso cada epoch iteracion\n",
        "#verbose: nos muestre lo que va haciendo\n",
        "#2. Guardar todo el modelo\n",
        "model_path = \"model/best_model.h5\"\n",
        "checkpoint_model = ModelCheckpoint(filepath=model_path, save_best_only=True, save_weights_only=False, save_freq='epoch', verbose=1, monitor='val_accuracy')\n",
        "#Nuevos cambios\n",
        "#save_weights_only: Ahora en false para que guarde estructura y pesos\n",
        "#save_best_inly: Solamente guarda los mejores\n",
        "#monitor: De donde va clasificar el mejor eneste caso de val acurracy pero esto cambia dependiendo lo que el modelo necesite para almacenar el mejor modelo para n funcion"
      ],
      "metadata": {
        "id": "dyjGhGZzlZxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo lo que hace para los pesos solamente\n",
        "es iterar y en cada epoch es decir iteracion este va guardando en la ruta los pesos y nos va indicando el mensaje\n",
        "\n",
        "Para el caso dos este itera y por cada iteracion va a guardar si solo si el modelo ve que el monitor es decir la funcion a monitoriar mejora , y este lo sobrecribe encaso de que encuentre un mejor modelo y lo guarda ahi\n",
        "\n",
        "***como utilizar?***\n",
        "\n",
        "Primero cargar unn modelo de donde va extraer esos valores\n",
        "\n",
        "***PARA PESOS:***\n",
        "\n",
        "crear un nuevo modelo (modelo).load_weights(cargar la ruta donde están los pesos guardados) de esa manera se cargan con los pesos del modelo anterior ya entrenado\n",
        "\n",
        "***PARA MODELO COMPLETO:***\n",
        "\n",
        "crear un nuevo modelo (modelo) = tf.keras.models.load_model(Ruta donde se guardó el mejor modelo)\n",
        "\n",
        "***Otras maneras manuales de guardar pesos y modelo:***\n",
        "\n",
        "Pesos:\n",
        "\n",
        "model.save_weights(path)\n",
        "\n",
        "Modelo:\n",
        "\n",
        "model.save(path)"
      ],
      "metadata": {
        "id": "amRzR187qqdV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.4 TensorBoard\n"
      ],
      "metadata": {
        "id": "HGYpZNcVsiaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from time import time"
      ],
      "metadata": {
        "id": "OtgtNlZUtLn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensorboard_ = TensorBoard(log_dir=f\"logs/{time()}\")\n",
        "#Log_dir= Directiro donde se almacenara el tensorboard\n",
        "#Time() Para poder guardar la ingfomacion del modelo con la hora don tiempos de ejecucion y demas"
      ],
      "metadata": {
        "id": "nXdVNyspqmuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementacion**\n",
        "\n",
        "una vez tenemos nuestro callback dentro del modelo , esté habrá sacado la infromacion\n",
        "para cargarlo tendríamos que hacer :\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "%tensorboard --logdir logs\n"
      ],
      "metadata": {
        "id": "_irgTVM5th4U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0QuzZIMotzLf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.5 Como implemenatr callbacks"
      ],
      "metadata": {
        "id": "OtI76ysLt5C5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "esto se ve en la parte de ajustar las redes neuronales\n",
        "\n",
        ".fit(\n",
        "  callbacks=[El callback que desean implementar]\n",
        ")\n",
        "\n",
        "Mas adelante se implementará un modelo con todo para tener una referencia lo unico que cambiaría sería el callback a utilizar"
      ],
      "metadata": {
        "id": "o2pbyfU0t9Qg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8 Guardar solamente la estructura de un modelo"
      ],
      "metadata": {
        "id": "9HuhD1nqJKeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Para el ejemplo utilizaré el modelo de Convolucion para implementarlo\n",
        "model_estructure = model_cnn.get_config()\n",
        "#Implementar la estructura en otro modelo\n",
        "model_with_estructure = tf.keras.Sequential.from_config(model_estructure)\n",
        "#Revisar la estructura de este\n",
        "model_with_estructure.summary()"
      ],
      "metadata": {
        "id": "bgtk9iLRuFty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9 Autotuner"
      ],
      "metadata": {
        "id": "F5Zns7iXLheV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El autotuner es una tecnica para buscar los hyperparametros dentro de las redes neuronales como lo son las neuronas o los learning rates , en este caso tenemos que lo que hacen es probar una cantidad de epocas con una combinacion y luego van probando otra hasta quedarse con la mejor combinacion\n",
        "cuando usamos hyperband este incluye el factor= n , donde se va encargar de usar menos recursos para encontrar esto, esto funciona porque agarra la cantidad de epocas y las divide entre el numero del factor dando una nueva catnidad de epocas , y entrena esa cantidad de epocas con diferentes combinaciones , se queda con 1/n_factor de esas combinaciones les da mas recursos para que se entrenen y leugo vuelve y se queda con 1/n_factor de esos anteriores , para seleccionar la mejor combinacion"
      ],
      "metadata": {
        "id": "Cyo1fnSfNhiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importar la librería para usar el autotuner\n",
        "!pip install -q -U keras-tuner\n",
        "import kerastuner as kt"
      ],
      "metadata": {
        "id": "aNro3dLEKR3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Funcion con el modelo con las posibles combinaciones\n",
        "def cnn_tuner(hp):\n",
        "  model_ = tf.keras.Sequential()\n",
        "  #Capas iniciales de limpieza y filtración\n",
        "  model_.add(tf.keras.layers.Conv2D(75, (3, 3), input_shape=(28, 28, 1), activation='relu'))\n",
        "  model_.add(tf.keras.layers.MaxPool2D((2, 2)))\n",
        "  model_.add(tf.keras.layers.Flatten())\n",
        "\n",
        "  #Combinaciones posbiles\n",
        "  hp_combinator = hp.Int('units', min_value=64, max_value=512, step=32)\n",
        "\n",
        "  #Capa de cambio\n",
        "  model_.add(tf.keras.layers.Dense(units=hp_combinator, activation='relu', kernel_regularizer=regularizer.l2(1e-5)))\n",
        "  model_.add(tf.keras.layers.Dropout(rate=0.2)) #Dropout para la capa previa\n",
        "\n",
        "  #Capas finales\n",
        "  model_.add(tf.keras.layers.Dense(128, kernel_regularizer=regularizer.l2(1e-5), activation='relu')) #(Probar combinaciones opcionales en esta capa, en este caso por recursos no)\n",
        "  model_.add(tf.keras.layers.Dropout(rate=0.2)) #Dropout para la capa previa\n",
        "  model_.add(tf.keras.layers.Dense(len(clases), activation='softmax'))\n",
        "\n",
        "  #Combinaciones posibles del Learning Rate\n",
        "  lr_combinator = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "  #Compilar el modelo y especificar que el optimizer es un combinador\n",
        "  model_.compile(optimizer=tf.keras.optimizers.Adam(lr_combinator), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model_"
      ],
      "metadata": {
        "id": "4FLSQW5fO5ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hyper_band = kt.Hyperband(\n",
        "    cnn_tuner, #Modelo donde se encuentran los parametros de combinaciones\n",
        "    objective='val_accuracy', #Sacar el mejor modelo respecto a la referencia que el proyecto necesite\n",
        "    max_epochs=20, #Cantidad maxima de epocas\n",
        "    factor=3, #Veces que va a probar diferentes epocas y combinaciones (Optimzar recursos)\n",
        "    directory='combinations/', #Donde va guardar los modelos\n",
        "    project_name='Tuner' #Nombre del proyecto\n",
        ")\n",
        "#Como entrnarlo\n",
        "#tuner.search(datos_train, epochs=epochs_puestos, validation_data=datos_validation)\n",
        "#Extraer mejore resultados: best_hps = tuner.get_best_hyperparameters(num_trails= 1)[0] #el numnero de trails es la cantidad de veces que va validar que los resultados finales sean correctos\n",
        "#instanciar modelo con la best_combination\n",
        "#hyper_model = tuner.hypermodel.build(best_hps) y entrenar con fit como se hace normal"
      ],
      "metadata": {
        "id": "Om2YvzPaUm6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10 Transfer Learning\n"
      ],
      "metadata": {
        "id": "oW2PDob-Zkt-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para el transfer learning es muy importante revisar los modelos los cuales vamos a usar y el que mejor se ajuste a nosotros ya que hay qeu cambiar los generadores con los cuales se entrenan los modelos , esto para que sea comatibles\n",
        "\n",
        "El tl consiste en cortar hasta cierto punto una estrctura de red neuronal con los pesos de esa red congelados para aprovechar los epsos y la estructura de una manera que generalice , cortamos a una parte para qeu no sea tan especfica e implementamos las capas finales con nuestras clases"
      ],
      "metadata": {
        "id": "KQJZfIC7Zolm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10.1 Nuevos generadores"
      ],
      "metadata": {
        "id": "_JOlDgiwbRpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "                                        #Ajustar los generadores para el moelo preentrenado\n",
        "#Cambios para este\n",
        "#Reajustar tamaño de imagenes para que sea compatible con el modelo preentrenado y reajustar la escala de colores con la que la escala del modelo preentrenado fue entrenado\n",
        "#Cambiar nombre de genrador a train_gen_pt -> pt -> PreenTrenado\n",
        "\n",
        "#---- Generador de entrenamiento ----\n",
        "train_gen_pt = train_gen_est.flow_from_directory(\n",
        "    train_path, #De dondé saldrán las imágenes\n",
        "    target_size=(150, 150), #El tamaño de las imágenes que nos dice el modelo PREENTRENADO\n",
        "    color_mode='rgb', #La escala de las imagenes que nuestro modelo preentrenado nos indica\n",
        "    class_mode='categorical', #Tipo de clase que hay\n",
        "    batch_size=(128), #Tamaño del lote en como va enviar las imágenes\n",
        "    subset='training' #Que tipo de set de datos será este\n",
        ")\n",
        "\n",
        "#---- Generador de validación  ----\n",
        "validation_gen_pt = test_gen_est.flow_from_directory(\n",
        "    test_path, #De dondé saldrán las imágenes\n",
        "    target_size=(150, 150), #El tamaño de las imágenes que nos dice el modelo PREENTRENADO\n",
        "    color_mode='rgb', #La escala de las imagenes que nuestro modelo preentrenado nos indica\n",
        "    class_mode='categorical', #Tipo de clase que hay\n",
        "    batch_size=(128), #Tamaño del lote en como va enviar las imágenes\n",
        "    subset='validation' #Que tipo de set de datos será este\n",
        ")\n",
        "\n",
        "#---- Generador de test ----\n",
        "test_gen_pt = test_gen_est.flow_from_directory(\n",
        "    test_path, #De dondé saldrán las imágenes\n",
        "    target_size=(150, 150), #El tamaño de las imágenes que nos dice el modelo PREENTRENADO\n",
        "    color_mode='rgb', #La escala de las imagenes que nuestro modelo preentrenado nos indica\n",
        "    class_mode='categorical', #Tipo de clase que hay\n",
        "    batch_size=(128), #Tamaño del lote en como va enviar las imágenes\n",
        "    #Al definir train y validation sets el set de test ya se reconoce automaticamente\n",
        ")"
      ],
      "metadata": {
        "id": "QavYZiuyXKj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10.2 Keras Preentrenado Model (Inception_resnet_v2)"
      ],
      "metadata": {
        "id": "-a5qLTJ7bWjZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este modelo se estuvo revisando para poder ajustarlo y ver como optimo para este ejemplo con nuestro ejemplo de lenguaje de señas\n",
        "\n",
        "link de keras con mas pt_models =\n",
        "\n",
        "[Keras Applications](https://keras.io/api/applications/)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "f5Z-VP9EbwqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pt_model_keras = tf.keras.applications.inception_v3.InceptionV3 #Modelo preentrenado\n",
        "pt_model = pt_model_keras(include_top=False, input_tensor=tf.keras.layers.Input(shape=(150, 150, 3)))\n",
        "#Include_top: Al momento de crear el modelo especficamos que no queremos las ultimas capas ya que contienen las clases de ese modelo no del nestro\n",
        "#Input_tensor: Importante ya que le indicamos que la primera capa van a ser nuestras entradas con ciertos tamaños que son los que tiene los generadores"
      ],
      "metadata": {
        "id": "3_-Q2V04bK9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Asignamos no entrenamiento a las capas ya que estas ya están entrenadas y solo queremos usar los pesos\n",
        "for layer in pt_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "#Revisamos estructura de la red neuronal como la tenemos\n",
        "pt_model.summary()"
      ],
      "metadata": {
        "id": "2FlpxRWCcgXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cortar la red hasta un punto donde no sea tan especficio respecto a lo que hizo (Depende como lo necesites)\n",
        "last_layer = pt_model.get_layer('mixed7')\n",
        "last_ouput = last_layer.output #Nos da las capas para usar hasta mixed 7"
      ],
      "metadata": {
        "id": "wW_bvJF9d9vN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Crear la Red con las capas previas y con las capas nuestras finales\n",
        "#API Funcional\n",
        "x = tf.keras.layers.Flatten()(last_ouput) #Flatten despues de mixed7\n",
        "x = tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=regularizer.l2(1e-5))(x)#Agregamos nueva capa casi llegando al final\n",
        "x = tf.keras.layers.Dropout(rate=0.2)(x) #Dropout para la anterior\n",
        "x = tf.keras.layers.Dense(len(clases), activation='softmax')(x) #Capa final con nuestras clases\n",
        "\n",
        "#Crear nuestro modelo con la red neuronal que acabamos de armar\n",
        "model_pt = tf.keras.Model(pt_model.input, x) #Especificar la entrada y la red o la salida que tiene\n",
        "#Rectificar que la red haya quedado como queriamos\n",
        "model_pt.summary()"
      ],
      "metadata": {
        "id": "Em0DVsCpgCwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenar el modelo preentrenado\n",
        "\n",
        "history = model_pt.fit(train_data(RESIZE), callbacks=[callback] , epochs=20, validation_data=validation_data(RESIZE))"
      ],
      "metadata": {
        "id": "S_eZQNZkijS2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11 Entrenamiento de modelos basicoss para ver como entrenar y visualizar"
      ],
      "metadata": {
        "id": "c1LLZxHeoFOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Modelo base creado previamente\n",
        "#En historypara almacenar los datos y graficar resultados\n",
        "history_base = model_base.fit(\n",
        "    train_gen,\n",
        "    epochs=20,\n",
        "    callbacks=[early_callback],\n",
        "    validation_data = validation_gen\n",
        ")"
      ],
      "metadata": {
        "id": "6LLM_wJToK_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Graficar resultados\n",
        "plot_history(history_base)"
      ],
      "metadata": {
        "id": "TfaShrxxp8SW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Modelo convolucional creado previamente\n",
        "hisstory_conv = model_cnn.fit(\n",
        "    train_gen,\n",
        "    epochs=20,\n",
        "    callbacks=[tensorboard_],\n",
        "    validation_data=validation_gen\n",
        ")"
      ],
      "metadata": {
        "id": "TjS05D2IsiGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(hisstory_conv)"
      ],
      "metadata": {
        "id": "__b9tiMEtkve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Usar tensorboard para ver el modelo\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs\n"
      ],
      "metadata": {
        "id": "mhtNhYiFyLsW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}